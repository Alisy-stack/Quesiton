{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation of some data\n",
    "np.random.seed (245)\n",
    "nobs =10000\n",
    "\n",
    "# Definition normalverteilte Features\n",
    "x1= np.random.normal(size=nobs ,scale=1) # ich definiere normal verteilte x1 \n",
    "x2= np.random.normal(size=nobs ,scale=1) # auch x2 ist normalverteilt\n",
    "x3= np.random.normal(size=nobs ,scale=1) # auch x3 ist normalverteilt\n",
    "x4= np.random.normal(size=nobs ,scale=1) # auch x4 ist normalverteilt\n",
    "x5= np.random.normal(size=nobs ,scale=1) # auch x5 ist normalverteilt\n",
    "\n",
    "# Dann werden Features in einer Matrix 端berf端hrt \n",
    "X= np.c_[np.ones((nobs ,1)),x1,x2,x3,x4,x5] \n",
    "\n",
    "\n",
    "y= np.cos(x1) + np.sin(x2) + 2*x3 + x4 + 0.01*x5 + np.random.normal(size=nobs , scale=0.01) # fehler ist normalverteilt-> y auch ist normalverteilt\n",
    "                                                                                            #  width irreducable error ist 0.01\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Neural Network\n",
    "### Hyper parameters\n",
    "#### ich habe nicht gleiche Aktivierungsfunktion f端r alle meiner Neuronen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learningrate\n",
    "LR=0.05\n",
    "\n",
    "\n",
    "# Number of Neurons\n",
    "Neuron_Out=1\n",
    "Neuron_Hidden1=64\n",
    "Neuron_Hidden2=32\n",
    "\n",
    "#The Activation function\n",
    "Activate_output='linear' # f端r letzte Schicht verwende ich linear\n",
    "Activate_hidden='relu' # unterschied ist Hidden-Layer-Neuronen werden nicht linear transformiert\n",
    "\n",
    "\n",
    "#The Optimizer\n",
    "Optimizer= SGD(lr=LR)\n",
    "\n",
    "\n",
    "# The loss function\n",
    "loss='mean_squared_error'\n",
    "\n",
    "# Splitting Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train , x_test , y_train , y_test = train_test_split(X, y, test_size =0.15, random_state =77)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/Anaconda/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py:1735: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                448       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,561\n",
      "Trainable params: 2,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Neural Network\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed (245)\n",
    "# As in Medium Essa\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "#Initialize the ANN\n",
    "model_ANN= Sequential()\n",
    "\n",
    "# Hidden Layer-> hier wird Hidden Layer definiert-> Anzahl der Neuronen hier sind 64, 32\n",
    "# input ist 6 (also 1,x1,x2,x3,x4,x5)-> one is the first column in X Matrix\n",
    "model_ANN.add(Dense(Neuron_Hidden1, activation=Activate_hidden, input_shape=(6,), use_bias=True))\n",
    "model_ANN.add(Dense(Neuron_Hidden2, activation=Activate_hidden, use_bias=True))\n",
    "\n",
    "#Output Layer-> hier wird Output-Layer defniniert\n",
    "model_ANN.add(Dense(Neuron_Out, activation=Activate_output,use_bias=True))\n",
    "model_ANN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ANN.compile(optimizer=Optimizer , loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Applications/Anaconda/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /Applications/Anaconda/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/125\n",
      "8500/8500 [==============================] - 2s 208us/step - loss: 0.2328\n",
      "Epoch 2/125\n",
      "8500/8500 [==============================] - 1s 80us/step - loss: 0.0477\n",
      "Epoch 3/125\n",
      "8500/8500 [==============================] - 1s 78us/step - loss: 0.0372\n",
      "Epoch 4/125\n",
      "8500/8500 [==============================] - 1s 90us/step - loss: 0.0216\n",
      "Epoch 5/125\n",
      "8500/8500 [==============================] - 1s 75us/step - loss: 0.0171\n",
      "Epoch 6/125\n",
      "8500/8500 [==============================] - 1s 71us/step - loss: 0.0186\n",
      "Epoch 7/125\n",
      "8500/8500 [==============================] - 1s 98us/step - loss: 0.0149\n",
      "Epoch 8/125\n",
      "8500/8500 [==============================] - 1s 78us/step - loss: 0.0118\n",
      "Epoch 9/125\n",
      "8500/8500 [==============================] - 1s 76us/step - loss: 0.0104\n",
      "Epoch 10/125\n",
      "8500/8500 [==============================] - 1s 88us/step - loss: 0.0108\n",
      "Epoch 11/125\n",
      "8500/8500 [==============================] - 1s 77us/step - loss: 0.0087\n",
      "Epoch 12/125\n",
      "8500/8500 [==============================] - 1s 75us/step - loss: 0.0086\n",
      "Epoch 13/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0072\n",
      "Epoch 14/125\n",
      "8500/8500 [==============================] - 1s 66us/step - loss: 0.0085\n",
      "Epoch 15/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0065\n",
      "Epoch 16/125\n",
      "8500/8500 [==============================] - 1s 68us/step - loss: 0.0063\n",
      "Epoch 17/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0056\n",
      "Epoch 18/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0056\n",
      "Epoch 19/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0062\n",
      "Epoch 20/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0060\n",
      "Epoch 21/125\n",
      "8500/8500 [==============================] - 1s 68us/step - loss: 0.0044\n",
      "Epoch 22/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0049\n",
      "Epoch 23/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0053\n",
      "Epoch 24/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0041\n",
      "Epoch 25/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0037\n",
      "Epoch 26/125\n",
      "8500/8500 [==============================] - 1s 68us/step - loss: 0.0043\n",
      "Epoch 27/125\n",
      "8500/8500 [==============================] - 1s 66us/step - loss: 0.0038\n",
      "Epoch 28/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0046\n",
      "Epoch 29/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0039\n",
      "Epoch 30/125\n",
      "8500/8500 [==============================] - 1s 68us/step - loss: 0.0038\n",
      "Epoch 31/125\n",
      "8500/8500 [==============================] - 1s 66us/step - loss: 0.0046\n",
      "Epoch 32/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0033\n",
      "Epoch 33/125\n",
      "8500/8500 [==============================] - 1s 66us/step - loss: 0.0034\n",
      "Epoch 34/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0038\n",
      "Epoch 35/125\n",
      "8500/8500 [==============================] - 1s 68us/step - loss: 0.0033\n",
      "Epoch 36/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0033\n",
      "Epoch 37/125\n",
      "8500/8500 [==============================] - 1s 68us/step - loss: 0.0035\n",
      "Epoch 38/125\n",
      "8500/8500 [==============================] - 1s 66us/step - loss: 0.0038\n",
      "Epoch 39/125\n",
      "8500/8500 [==============================] - 1s 68us/step - loss: 0.0033\n",
      "Epoch 40/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0030\n",
      "Epoch 41/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0031\n",
      "Epoch 42/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0034\n",
      "Epoch 43/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0027\n",
      "Epoch 44/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0030\n",
      "Epoch 45/125\n",
      "8500/8500 [==============================] - 1s 66us/step - loss: 0.0030\n",
      "Epoch 46/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0024\n",
      "Epoch 47/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0026\n",
      "Epoch 48/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0026\n",
      "Epoch 49/125\n",
      "8500/8500 [==============================] - 1s 66us/step - loss: 0.0025\n",
      "Epoch 50/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0029\n",
      "Epoch 51/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0025\n",
      "Epoch 52/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0023\n",
      "Epoch 53/125\n",
      "8500/8500 [==============================] - 1s 68us/step - loss: 0.0025\n",
      "Epoch 54/125\n",
      "8500/8500 [==============================] - 1s 68us/step - loss: 0.0027\n",
      "Epoch 55/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0023\n",
      "Epoch 56/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0023\n",
      "Epoch 57/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0023\n",
      "Epoch 58/125\n",
      "8500/8500 [==============================] - 1s 68us/step - loss: 0.0022\n",
      "Epoch 59/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0022\n",
      "Epoch 60/125\n",
      "8500/8500 [==============================] - 1s 69us/step - loss: 0.0024\n",
      "Epoch 61/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0023\n",
      "Epoch 62/125\n",
      "8500/8500 [==============================] - 1s 66us/step - loss: 0.0023\n",
      "Epoch 63/125\n",
      "8500/8500 [==============================] - 1s 68us/step - loss: 0.0022\n",
      "Epoch 64/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0020\n",
      "Epoch 65/125\n",
      "8500/8500 [==============================] - 1s 68us/step - loss: 0.0022\n",
      "Epoch 66/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0020\n",
      "Epoch 67/125\n",
      "8500/8500 [==============================] - 1s 68us/step - loss: 0.0020\n",
      "Epoch 68/125\n",
      "8500/8500 [==============================] - 1s 68us/step - loss: 0.0021\n",
      "Epoch 69/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0019\n",
      "Epoch 70/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0023\n",
      "Epoch 71/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0021\n",
      "Epoch 72/125\n",
      "8500/8500 [==============================] - 1s 68us/step - loss: 0.0020\n",
      "Epoch 73/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0023\n",
      "Epoch 74/125\n",
      "8500/8500 [==============================] - 1s 68us/step - loss: 0.0021\n",
      "Epoch 75/125\n",
      "8500/8500 [==============================] - 1s 69us/step - loss: 0.0024\n",
      "Epoch 76/125\n",
      "8500/8500 [==============================] - 1s 69us/step - loss: 0.0018\n",
      "Epoch 77/125\n",
      "8500/8500 [==============================] - 1s 68us/step - loss: 0.0018\n",
      "Epoch 78/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0021\n",
      "Epoch 79/125\n",
      "8500/8500 [==============================] - 1s 68us/step - loss: 0.0019\n",
      "Epoch 80/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0017\n",
      "Epoch 81/125\n",
      "8500/8500 [==============================] - 1s 68us/step - loss: 0.0018\n",
      "Epoch 82/125\n",
      "8500/8500 [==============================] - 1s 68us/step - loss: 0.0019\n",
      "Epoch 83/125\n",
      "8500/8500 [==============================] - 1s 68us/step - loss: 0.0018\n",
      "Epoch 84/125\n",
      "8500/8500 [==============================] - 1s 68us/step - loss: 0.0018\n",
      "Epoch 85/125\n",
      "8500/8500 [==============================] - 1s 68us/step - loss: 0.0016\n",
      "Epoch 86/125\n",
      "8500/8500 [==============================] - 1s 68us/step - loss: 0.0018\n",
      "Epoch 87/125\n",
      "8500/8500 [==============================] - 1s 68us/step - loss: 0.0017\n",
      "Epoch 88/125\n",
      "8500/8500 [==============================] - 1s 68us/step - loss: 0.0021\n",
      "Epoch 89/125\n",
      "8500/8500 [==============================] - 1s 68us/step - loss: 0.0014\n",
      "Epoch 90/125\n",
      "8500/8500 [==============================] - 1s 68us/step - loss: 0.0017\n",
      "Epoch 91/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8500/8500 [==============================] - 1s 66us/step - loss: 0.0019\n",
      "Epoch 92/125\n",
      "8500/8500 [==============================] - 1s 66us/step - loss: 0.0017\n",
      "Epoch 93/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0015\n",
      "Epoch 94/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0014\n",
      "Epoch 95/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0016\n",
      "Epoch 96/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0020\n",
      "Epoch 97/125\n",
      "8500/8500 [==============================] - 1s 66us/step - loss: 0.0016\n",
      "Epoch 98/125\n",
      "8500/8500 [==============================] - 1s 66us/step - loss: 0.0015\n",
      "Epoch 99/125\n",
      "8500/8500 [==============================] - 1s 66us/step - loss: 0.0015\n",
      "Epoch 100/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0017\n",
      "Epoch 101/125\n",
      "8500/8500 [==============================] - 1s 66us/step - loss: 0.0015\n",
      "Epoch 102/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0016\n",
      "Epoch 103/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0016\n",
      "Epoch 104/125\n",
      "8500/8500 [==============================] - 1s 66us/step - loss: 0.0014\n",
      "Epoch 105/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0015\n",
      "Epoch 106/125\n",
      "8500/8500 [==============================] - 1s 68us/step - loss: 0.0014\n",
      "Epoch 107/125\n",
      "8500/8500 [==============================] - 1s 68us/step - loss: 0.0015\n",
      "Epoch 108/125\n",
      "8500/8500 [==============================] - 1s 84us/step - loss: 0.0016\n",
      "Epoch 109/125\n",
      "8500/8500 [==============================] - 1s 67us/step - loss: 0.0015\n",
      "Epoch 110/125\n",
      "8500/8500 [==============================] - 1s 72us/step - loss: 0.0018\n",
      "Epoch 111/125\n",
      "8500/8500 [==============================] - 1s 83us/step - loss: 0.0015\n",
      "Epoch 112/125\n",
      "8500/8500 [==============================] - 1s 90us/step - loss: 0.0015\n",
      "Epoch 113/125\n",
      "8500/8500 [==============================] - 1s 86us/step - loss: 0.0013\n",
      "Epoch 114/125\n",
      "8500/8500 [==============================] - 1s 87us/step - loss: 0.0015\n",
      "Epoch 115/125\n",
      "8500/8500 [==============================] - 1s 106us/step - loss: 0.0014 0s - loss: 0.001\n",
      "Epoch 116/125\n",
      "8500/8500 [==============================] - 1s 93us/step - loss: 0.0015\n",
      "Epoch 117/125\n",
      "8500/8500 [==============================] - 1s 86us/step - loss: 0.0014\n",
      "Epoch 118/125\n",
      "8500/8500 [==============================] - 1s 86us/step - loss: 0.0013\n",
      "Epoch 119/125\n",
      "8500/8500 [==============================] - 1s 83us/step - loss: 0.0015\n",
      "Epoch 120/125\n",
      "8500/8500 [==============================] - 1s 95us/step - loss: 0.0014\n",
      "Epoch 121/125\n",
      "8500/8500 [==============================] - 1s 81us/step - loss: 0.0016: 0s - los\n",
      "Epoch 122/125\n",
      "8500/8500 [==============================] - 1s 74us/step - loss: 0.0017\n",
      "Epoch 123/125\n",
      "8500/8500 [==============================] - 1s 74us/step - loss: 0.0013\n",
      "Epoch 124/125\n",
      "8500/8500 [==============================] - 1s 77us/step - loss: 0.0014\n",
      "Epoch 125/125\n",
      "8500/8500 [==============================] - 1s 80us/step - loss: 0.0013\n"
     ]
    }
   ],
   "source": [
    "#Fit the model\n",
    "history_ANN=model_ANN.fit(\n",
    "x_train, # training data\n",
    "y_train, # training targets\n",
    "epochs=125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_ANN.history['loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE ANN: 0.0008449917503000481\n"
     ]
    }
   ],
   "source": [
    "y_pred_ANN=model_ANN.predict(x_test) \n",
    "print(\"MSE ANN:\", mean_squared_error(y_test, y_pred_ANN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0008747289417145881\n",
      "0.0008449917503000481\n"
     ]
    }
   ],
   "source": [
    "# to better understand\n",
    "ANN_pred_IS=model_ANN.predict(x_train)\n",
    "ANN_pred_OOS=model_ANN.predict(x_test)\n",
    "\n",
    "print(mean_squared_error(y_train, ANN_pred_IS))\n",
    "print(mean_squared_error(y_test, ANN_pred_OOS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the Jacobian Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobian_tensorflow(x):    \n",
    "    jacobian_matrix = []\n",
    "    for m in range(Neuron_Out):\n",
    "        # We iterate over the M elements of the output vector\n",
    "        grad_func = tf.gradients(model_ANN.output[:, m], model_ANN.input)\n",
    "        gradients = sess.run(grad_func, feed_dict={model_ANN.input: x.reshape((1, x.size))})\n",
    "        jacobian_matrix.append(gradients[0][0,:])\n",
    "        \n",
    "    return np.array(jacobian_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (1, 9000) for Tensor 'dense_4_input:0', which has shape '(?, 6)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-724878a2cffb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjacobian_tensorflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-e2447eb9114e>\u001b[0m in \u001b[0;36mjacobian_tensorflow\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m# We iterate over the M elements of the output vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mgrad_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ANN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_ANN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mmodel_ANN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mjacobian_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/Anaconda/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/Anaconda/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1149\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1150\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (1, 9000) for Tensor 'dense_4_input:0', which has shape '(?, 6)'"
     ]
    }
   ],
   "source": [
    "jacobian_tensorflow(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
